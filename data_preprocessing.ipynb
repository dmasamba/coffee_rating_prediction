{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a9de04a",
   "metadata": {},
   "source": [
    "#### Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d9989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65cbb63",
   "metadata": {},
   "source": [
    "#### Download NLTK resources (only needed first time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84ace82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/danielmasamba/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/danielmasamba/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/danielmasamba/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77425ca0",
   "metadata": {},
   "source": [
    "#### Define custom text preprocessor & tokenizer\n",
    "We will: \n",
    "* Remove HTML-tag and any residual markup\n",
    "* Lowercase all text\n",
    "* Remove punctuation and digits\n",
    "* Tokenize on whitespace or with a regex tokenizer\n",
    "* Remove stop-word using NLTK standard English list\n",
    "* Porter Stemming to reduce terms to root forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c928524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer    = PorterStemmer()\n",
    "\n",
    "def custom_preprocessor(text: str) -> str:\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove digits\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    # Remove punctuation (keep only word chars and whitespace)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    return text\n",
    "\n",
    "def custom_tokenizer(text: str) -> list[str]:\n",
    "    # Basic word tokenization\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Stop-word removal\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    # Stemming\n",
    "    tokens = [stemmer.stem(t) for t in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25912ef0",
   "metadata": {},
   "source": [
    "#### Load and view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e9e7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/X_train.csv')\n",
    "y_train = pd.read_csv('data/y_train.csv')\n",
    "X_test  = pd.read_csv('data/X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a24d772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coffee_id</th>\n",
       "      <th>roaster</th>\n",
       "      <th>roast</th>\n",
       "      <th>origin</th>\n",
       "      <th>100g_USD</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1014</td>\n",
       "      <td>Kakalove Cafe</td>\n",
       "      <td>Medium-Light</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>11.33</td>\n",
       "      <td>Delicate, fruit-forward. Blueberry, molasses, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>Port of Mokha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yemen</td>\n",
       "      <td>39.68</td>\n",
       "      <td>Deep yet soaring, vertically complex. Dried bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1094</td>\n",
       "      <td>Simon Hsieh Aroma Roast Coffees</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>12.04</td>\n",
       "      <td>Evaluated as espresso. Richly chocolaty, compl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142</td>\n",
       "      <td>JBC Coffee Roasters</td>\n",
       "      <td>Medium-Light</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>5.51</td>\n",
       "      <td>Floral, bright, citrusy, balanced. Star jasmin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>647</td>\n",
       "      <td>Roast House</td>\n",
       "      <td>Medium-Light</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>4.19</td>\n",
       "      <td>Delicate, sweetly spice-toned. Pink peppercorn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>898</td>\n",
       "      <td>Green Stone Coffee</td>\n",
       "      <td>Medium-Light</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>9.24</td>\n",
       "      <td>Rich-toned, deeply aromatic. Black currant, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>384</td>\n",
       "      <td>Home in Harmony</td>\n",
       "      <td>Medium-Light</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>4.93</td>\n",
       "      <td>Cleanly fruit-toned, delicately sweet-tart. Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>588</td>\n",
       "      <td>David's Nose</td>\n",
       "      <td>Light</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>5.66</td>\n",
       "      <td>Richly aromatic, sweetly tart. Boysenberry, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>1180</td>\n",
       "      <td>El Gran Cafe</td>\n",
       "      <td>Medium-Light</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>5.88</td>\n",
       "      <td>Evaluated as espresso. Multi-layered, complex....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>200</td>\n",
       "      <td>Kakalove Cafe</td>\n",
       "      <td>Medium-Light</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>3.89</td>\n",
       "      <td>Crisp, citrusy, deeply sweet. Lemon verbena, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>620 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coffee_id                          roaster         roast     origin  \\\n",
       "0         1014                    Kakalove Cafe  Medium-Light     Taiwan   \n",
       "1         1000                    Port of Mokha           NaN      Yemen   \n",
       "2         1094  Simon Hsieh Aroma Roast Coffees        Medium      Kenya   \n",
       "3          142              JBC Coffee Roasters  Medium-Light   Ethiopia   \n",
       "4          647                      Roast House  Medium-Light   Ethiopia   \n",
       "..         ...                              ...           ...        ...   \n",
       "615        898               Green Stone Coffee  Medium-Light      Kenya   \n",
       "616        384                  Home in Harmony  Medium-Light   Ethiopia   \n",
       "617        588                     David's Nose         Light   Ethiopia   \n",
       "618       1180                     El Gran Cafe  Medium-Light  Guatemala   \n",
       "619        200                    Kakalove Cafe  Medium-Light   Ethiopia   \n",
       "\n",
       "     100g_USD                                             review  \n",
       "0       11.33  Delicate, fruit-forward. Blueberry, molasses, ...  \n",
       "1       39.68  Deep yet soaring, vertically complex. Dried bl...  \n",
       "2       12.04  Evaluated as espresso. Richly chocolaty, compl...  \n",
       "3        5.51  Floral, bright, citrusy, balanced. Star jasmin...  \n",
       "4        4.19  Delicate, sweetly spice-toned. Pink peppercorn...  \n",
       "..        ...                                                ...  \n",
       "615      9.24  Rich-toned, deeply aromatic. Black currant, to...  \n",
       "616      4.93  Cleanly fruit-toned, delicately sweet-tart. Ra...  \n",
       "617      5.66  Richly aromatic, sweetly tart. Boysenberry, st...  \n",
       "618      5.88  Evaluated as espresso. Multi-layered, complex....  \n",
       "619      3.89  Crisp, citrusy, deeply sweet. Lemon verbena, c...  \n",
       "\n",
       "[620 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd28dd19",
   "metadata": {},
   "source": [
    "#### Drop coffee_id column but keep aside to use for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a6678e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = X_train.pop('coffee_id')\n",
    "test_ids  = X_test.pop('coffee_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21f4e0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1014\n",
       "1      1000\n",
       "2      1094\n",
       "3       142\n",
       "4       647\n",
       "       ... \n",
       "615     898\n",
       "616     384\n",
       "617     588\n",
       "618    1180\n",
       "619     200\n",
       "Name: coffee_id, Length: 620, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868db584",
   "metadata": {},
   "source": [
    "#### Build sub-pipelines for attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb98acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric pipeline for 100g-USD\n",
    "num_pipe = Pipeline([\n",
    "    # log(1+x) to reduce skew\n",
    "    ('log',   FunctionTransformer(np.log1p, validate=True)),\n",
    "    # standardize\n",
    "    ('scale', StandardScaler()),\n",
    "])\n",
    "\n",
    "# Categorical pipeline for roaster, roast, origin\n",
    "cat_pipe = OneHotEncoder(\n",
    "    handle_unknown='ignore',\n",
    "    sparse_output=False\n",
    ")\n",
    "\n",
    "# Text pipeline for review\n",
    "txt_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        preprocessor=custom_preprocessor,\n",
    "        tokenizer=custom_tokenizer,\n",
    "        stop_words=None,        # we handle stop‐words in tokenizer\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=5,\n",
    "        max_df=0.95,\n",
    "        max_features=1000\n",
    "    )),\n",
    "    ('select', SelectKBest(chi2, k=500)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40630f07",
   "metadata": {},
   "source": [
    "#### Combine everything into a ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b5d2f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipe,   ['100g_USD']),\n",
    "    ('cat', cat_pipe,   ['roaster', 'roast', 'origin']),\n",
    "    ('txt', txt_pipe,   'review'),\n",
    "], remainder='drop', verbose_feature_names_out=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8401fcfc",
   "metadata": {},
   "source": [
    "#### Fit the preprocessing on the training data, transform both train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7efd407c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielmasamba/anaconda3/envs/dan/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train_transformed = preprocessor.fit_transform(X_train, y_train.values.ravel())\n",
    "X_test_transformed  = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c316ae4",
   "metadata": {},
   "source": [
    "#### Inspect outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a9859f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed X_train shape: (620, 728)\n",
      "Transformed X_test  shape: (267, 728)\n",
      "############################################################\n",
      "[[ 0.43423367  0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 2.215536    0.          0.         ...  0.          0.\n",
      "   0.18672739]\n",
      " [ 0.51777921  0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.48486757  0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.43637064  0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.94586458  0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformed X_train shape:\", X_train_transformed.shape)\n",
    "print(\"Transformed X_test  shape:\", X_test_transformed.shape)\n",
    "print(\"#\"*60)\n",
    "print(X_train_transformed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
