{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "508a1291",
   "metadata": {},
   "source": [
    "#### Import needed dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bae2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score, classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af2c681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs all cells in data_preprocessing.ipynb\n",
    "%run data_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6af8633",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3fb5e3",
   "metadata": {},
   "source": [
    "## Train and evaluate without cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f9c819",
   "metadata": {},
   "source": [
    "#### Simple train/validation split (no CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6d6c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train_transformed, \n",
    "    y_train.values.ravel(),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a48160c",
   "metadata": {},
   "source": [
    "#### Fit & evaluate Decision tree and KNN classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fe60c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_tr, y_tr)\n",
    "y_val_pred = dt.predict(X_val)\n",
    "print(\"Decision Tree\\n\", classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b7d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_tr, y_tr)\n",
    "print(\"KNN\\n\", classification_report(y_val, knn.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5296ecd",
   "metadata": {},
   "source": [
    "#### PyTorch MLP on a fixed split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap into DataLoader\n",
    "train_ds = TensorDataset(torch.from_numpy(X_tr).float(), torch.from_numpy(y_tr).float())\n",
    "val_ds   = TensorDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).float())\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8945ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim,128), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(128,64),    nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(64,1)\n",
    "        )\n",
    "    def forward(self,x): return self.net(x).squeeze(1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP(X_tr.shape[1]).to(device)\n",
    "opt   = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "crit  = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# training loop\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    for xb,yb in train_loader:\n",
    "        xb,yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad()\n",
    "        loss = crit(model(xb), yb)\n",
    "        loss.backward(); opt.step()\n",
    "\n",
    "# evaluate\n",
    "\n",
    "model.eval()\n",
    "preds, trues = [], []\n",
    "with torch.no_grad():\n",
    "    for xb,yb in val_loader:\n",
    "        xb = xb.to(device)\n",
    "        probs = torch.sigmoid(model(xb)).cpu().numpy()\n",
    "        preds.extend((probs>0.5).astype(int))\n",
    "        trues.extend(yb.numpy().astype(int))\n",
    "\n",
    "print(\"MLP\\n\", classification_report(trues, preds))\n",
    "print(\"MLP F1:\", f1_score(trues, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428f22a2",
   "metadata": {},
   "source": [
    "## Train and evaluate with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ff3a6b",
   "metadata": {},
   "source": [
    "#### Flatten labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff1c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_train.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfd7c33",
   "metadata": {},
   "source": [
    "#### Decision Tree and KNN via scikit-learn CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1914aa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "save_dir = \"models/\"\n",
    "\n",
    "models = [\n",
    "    # Decision Tree\n",
    "    (\"Decision Tree\",\n",
    "     DecisionTreeClassifier(\n",
    "         max_depth=5,\n",
    "         min_samples_split=2,\n",
    "         min_samples_leaf=1,\n",
    "         random_state=42\n",
    "     )\n",
    "    ),\n",
    "    # KNN\n",
    "    (\"KNN\",\n",
    "     KNeighborsClassifier(\n",
    "         n_neighbors=5,\n",
    "        weights='uniform'\n",
    "     )\n",
    "    )\n",
    "]\n",
    "\n",
    "cv_results = {}\n",
    "model_avg_val_f1 = {}\n",
    "\n",
    "# run cross_validate for each model\n",
    "for name, clf in models:\n",
    "    pipe = Pipeline([\n",
    "        (\"preproc\", preprocessor),\n",
    "        (\"clf\",      clf)\n",
    "    ])\n",
    "    results = cross_validate(\n",
    "        pipe,\n",
    "        X_train,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=f1_scorer,\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    cv_results[name] = results\n",
    "\n",
    "    # print per‐fold F1\n",
    "    train_f1 = results['train_score']\n",
    "    val_f1   = results['test_score']\n",
    "    print(f\"\\n{name} F1 scores by fold:\")\n",
    "    for fold, (tr, va) in enumerate(zip(train_f1, val_f1), start=1):\n",
    "        print(f\"  Fold {fold:>1d}: train F1 = {tr:.3f},  val F1 = {va:.3f}\")\n",
    "    \n",
    "    # Save the model's average validation F1 scores\n",
    "    # Later be used to determine the best of the 3 models\n",
    "    model_avg_val_f1[name] = val_f1.mean()\n",
    "    \n",
    "    # Final fit on all training data & save\n",
    "    pipe.fit(X_train, y)\n",
    "    fname = f\"{name.lower().replace(' ', '_')}.pkl\"\n",
    "    path  = os.path.join(save_dir, fname)\n",
    "    joblib.dump(pipe, path)\n",
    "    print(f\"→ Saved `{name}` pipeline to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79f0b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build DataFrame of results\n",
    "rows = []\n",
    "for model_name, res in cv_results.items():\n",
    "    for fold_idx, (train_score, test_score, fit_time, score_time) in enumerate(\n",
    "        zip(res['train_score'], res['test_score'], res['fit_time'], res['score_time']),\n",
    "        start=1\n",
    "    ):\n",
    "        rows.append({\n",
    "            'model'       : model_name,\n",
    "            'fold'        : fold_idx,\n",
    "            'train_f1'    : train_score,\n",
    "            'val_f1'      : test_score,\n",
    "            'fit_seconds' : fit_time,\n",
    "            'score_seconds': score_time\n",
    "        })\n",
    "\n",
    "df_cv = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56277e87",
   "metadata": {},
   "source": [
    "#### PyTorch MLP with 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f496364",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device: {device}\\n\")\n",
    "\n",
    "# First, transform the entire feature matrix once:\n",
    "X_all = preprocessor.fit_transform(X_train, y)\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS      = 20\n",
    "BATCH_SIZE  = 32\n",
    "LR          = 1e-3\n",
    "INPUT_DIM   = X_all.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9003bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple MLP for binary classification\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1)            # single logit\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)  # (batch,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02247e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_and_eval(train_idx, val_idx, fold=None):\n",
    "    # Split data\n",
    "    X_tr = torch.from_numpy(X_all[train_idx]).float()\n",
    "    y_tr = torch.from_numpy(y[train_idx]).float()\n",
    "    X_va = torch.from_numpy(X_all[val_idx]).float()\n",
    "    y_va = torch.from_numpy(y[val_idx]).float()\n",
    "\n",
    "    # DataLoaders\n",
    "    tr_loader = DataLoader(TensorDataset(X_tr, y_tr),\n",
    "                           batch_size=BATCH_SIZE, shuffle=True)\n",
    "    va_loader = DataLoader(TensorDataset(X_va, y_va),\n",
    "                           batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Model, loss, optimizer\n",
    "    model     = MLP(INPUT_DIM).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for xb, yb in tr_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss   = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item() * xb.size(0)\n",
    "        train_losses.append(running_train_loss / len(tr_loader.dataset))\n",
    "\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in va_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                loss_val = criterion(model(xb), yb)\n",
    "                running_val_loss += loss_val.item() * xb.size(0)\n",
    "        val_losses.append(running_val_loss / len(va_loader.dataset))\n",
    "    \n",
    "    torch.save(model.state_dict(), f\"{save_dir}/MLP.pth\")\n",
    "\n",
    "    # Plot learning curves\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(range(1, EPOCHS+1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, EPOCHS+1), val_losses,   label='Val   Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('BCEWithLogitsLoss')\n",
    "    plt.title(f'MLP Learning Curves' + (f' — Fold {fold}' if fold is not None else ''))\n",
    "    plt.legend()\n",
    "\n",
    "    # Ensure directory exists and save\n",
    "    os.makedirs('plots', exist_ok=True)\n",
    "    fname = f'plots/mlp_learning_curve'\n",
    "    if fold is not None:\n",
    "        fname += f'_fold{fold}'\n",
    "    fname += '.png'\n",
    "    plt.savefig(fname, bbox_inches='tight', dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    # Final F1 on validation fold\n",
    "    model.eval()\n",
    "    preds_tr, trues_tr = [], []\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for xb, yb in tr_loader:\n",
    "            xb = xb.to(device)\n",
    "            probs = torch.sigmoid(model(xb)).cpu().numpy()\n",
    "            preds_tr.extend((probs > 0.5).astype(int))\n",
    "            trues_tr.extend(yb.numpy().astype(int))\n",
    " \n",
    "        for xb, yb in va_loader:\n",
    "            xb = xb.to(device)\n",
    "            probs = torch.sigmoid(model(xb)).cpu().numpy()\n",
    "            preds.extend((probs > 0.5).astype(int))\n",
    "            trues.extend(yb.numpy().astype(int))\n",
    "\n",
    "    return f1_score(trues_tr, preds_tr), f1_score(trues, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6885ee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 5-fold CV\n",
    "mlp_scores = []\n",
    "for fold, (tr_idx, va_idx) in enumerate(cv.split(X_all, y), start=1):\n",
    "    f1_tr, f1 = train_and_eval(tr_idx, va_idx, fold=fold)\n",
    "    mlp_scores.append(f1)\n",
    "    print(f\"MLP Fold {fold} →  F1 (training) = {f1_tr:3f} F1 (val) = {f1:.3f}\")\n",
    "\n",
    "model_avg_val_f1[\"MLP\"] = np.mean(np.array(mlp_scores))\n",
    "\n",
    "print(f\"\\nMLP  → mean F1 = {np.mean(mlp_scores):.3f},  std = {np.std(mlp_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5380a630",
   "metadata": {},
   "source": [
    "#### Plot bar chart for Decision Tree, KNN, and MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4db07c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small DataFrame for the MLP\n",
    "df_mlp = pd.DataFrame({\n",
    "    'model': ['MLP'] * len(mlp_scores),\n",
    "    'fold' : list(range(1, len(mlp_scores) + 1)),\n",
    "    'val_f1': mlp_scores\n",
    "})\n",
    "\n",
    "# Combine with your existing DT/KNN results\n",
    "# We only need model & val_f1 for the bar chart:\n",
    "df_all = pd.concat([\n",
    "    df_cv[['model','fold','val_f1']],\n",
    "    df_mlp\n",
    "], ignore_index=True)\n",
    "\n",
    "# Compute means and stds over val_f1 by model\n",
    "grouped = df_all.groupby('model')['val_f1']\n",
    "means = grouped.mean()\n",
    "stds  = grouped.std()\n",
    "\n",
    "# Plot bar chart with error bars\n",
    "plt.figure(figsize=(6,4))\n",
    "bars = plt.bar(\n",
    "    means.index,\n",
    "    means.values,\n",
    "    yerr=stds.values,\n",
    "    capsize=5,\n",
    "    alpha=0.8\n",
    ")\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Mean 5-fold Val F1\")\n",
    "plt.title(\"Cross-Validated F1 by Model\")\n",
    "\n",
    "# Annotate each bar with its mean value\n",
    "for bar, m in zip(bars, means.values):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width()/2,\n",
    "        m + 0.01,\n",
    "        f\"{m:.3f}\",\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "# Save the figure\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "plt.savefig('plots/cv_f1_by_model_all.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "# Display it\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c851e383",
   "metadata": {},
   "source": [
    "#### Plot confusion matrices for Decision Tree, KNN, and MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d5cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure output directory\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "\n",
    "def plot_cm(cm, model_name):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    im = plt.imshow(cm, cmap='Blues', interpolation='nearest')\n",
    "    plt.title(f\"{model_name} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "\n",
    "    # set proper ticks and labels\n",
    "    classes = ['0','1']\n",
    "    plt.xticks(np.arange(len(classes)), classes)\n",
    "    plt.yticks(np.arange(len(classes)), classes)\n",
    "\n",
    "    # annotate with contrasting text color\n",
    "    thresh = cm.max() / 2\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            color = \"white\" if cm[i, j] > thresh else \"black\"\n",
    "            plt.text(j, i, f\"{cm[i, j]:d}\",\n",
    "                     ha='center', va='center',\n",
    "                     color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs('plots', exist_ok=True)\n",
    "    plt.savefig(f\"plots/{model_name.lower().replace(' ','_')}_cm.png\",\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# ——— Decision Tree & KNN———\n",
    "X_tr_raw, X_val_raw, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train.values.ravel(),\n",
    "    test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "for name, clf in models:\n",
    "\n",
    "    pipe.fit(X_tr_raw, y_tr)\n",
    "    y_pred = pipe.predict(X_val_raw)    # also DataFrame\n",
    "\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    plot_cm(cm, name)\n",
    "\n",
    "# ——— MLP ———\n",
    "cm_mlp = confusion_matrix(trues, preds)\n",
    "plot_cm(cm_mlp, \"MLP\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
